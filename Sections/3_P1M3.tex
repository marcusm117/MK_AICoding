% =============================================================================
% Part I / Market 3: Specialized Agents/Tools for SE
% =============================================================================

\section{Market 3: Specialized Agents/Tools for Software Engineering}

\begin{frame}{Market 3: Scope \& Definition}
\justifying
\small
\begin{itemize}
  \item \textbf{Research Object:} Purpose-built AI agents and tools optimized for specific software engineering stages---distinct from general-purpose IDEs/agents (Market 2) that attempt broad coverage.

  \item \textbf{Six Sub-Markets:}
  \begin{enumerate}
    \item \textbf{Documentation / Knowledge:} DeepWiki, Mintlify, Swimm, ReadMe, GitBook, Notion AI, Sourcegraph.
    \item \textbf{Spec / Architecture / Design:} Figma Dev Mode, Postman, Stoplight, Eraser, v0, Fern.
    \item \textbf{Testing / QA:} Diffblue, Momentic, Mabl, Applitools, BrowserStack, Launchable.
    \item \textbf{Code Review / PR Workflow:} CodeRabbit, Qodo, Graphite, SonarQube, CodeScene, LinearB.
    \item \textbf{DevOps / Infrastructure:} Pulumi Neo, env0, Spacelift, Kubiya, Port, Backstage.
    \item \textbf{Security / Compliance:} Snyk, Semgrep, Socket, GitGuardian, Vanta, Drata.
  \end{enumerate}

  \item \textbf{Core Assessment Dimensions:} Three dimensions determine whether a vertical can sustain stand-alone vendors:
  \begin{enumerate}
    \item \textbf{Market Size} $\rightarrow$ TAM for each vertical---is the segment large enough to support dedicated vendors?
    \item \textbf{Technical Moat} $\rightarrow$ what domain-specific capabilities cannot be easily replicated by Market 2 players?
    \item \textbf{AI Potential} $\rightarrow$ what percentage of the workflow can AI fully automate vs. requiring human judgment?
  \end{enumerate}
\end{itemize}
\end{frame}

% =============================================================================
% Sub-Market 1: Documentation / Knowledge / Onboarding
% =============================================================================

\begin{frame}{Market 3.1: Documentation / Knowledge---Key Players}
\input{Tables/P1M3-documentation.tex}
\end{frame}

\begin{frame}{Market 3.1: Documentation / Knowledge---Analysis}
\justifying
\small
\begin{itemize}
  \item \textbf{Market Size (\$2--4B TAM):} Developer documentation tools represent a \textcolor{red}{\$2--4B} addressable market including API docs, internal wikis, and code-to-doc automation. \citelink{https://readme.com/}{ReadMe} (6,000+ companies), \citelink{https://mintlify.com/}{Mintlify} (2,500+ companies), and \citelink{https://www.gitbook.com/}{GitBook} (1M+ docs) have carved meaningful niches. However, \citelink{https://www.atlassian.com/software/confluence}{Confluence} (300k+ customers) and \citelink{https://www.notion.so/}{Notion} (100M+ users) dominate the broader knowledge management space---documentation specialists must differentiate on developer-specific workflows.

  \item \textbf{Technical Moat (Medium):} The moat is \textbf{not ``LLM text generation''}---it's (1) \textbf{repo-grounded understanding} + (2) \textbf{continuous freshness} (diff-aware regeneration, PR hooks) + (3) \textbf{workflow embedding} (ownership graphs, incident history). \citelink{https://swimm.io/}{Swimm} auto-updates docs when code changes; \citelink{https://cognition.ai/blog/deepwiki}{DeepWiki} builds architecture wikis from codebase analysis. The moat is \textbf{provenance and traceability}, not AI capability per se.

  \item \textbf{AI Potential (High---70--90\%):} Documentation is among the \textcolor{red}{highest AI automation potential} verticals. The ceiling: \textbf{semantic accuracy + accountability}---orgs need humans for ``source-of-truth'' claims unless tools offer strong provenance (links to commits, PRs, design decisions). \citelink{https://www.mintlify.com/blog/mintlify-acquires-trieve-to-improve-rag-search-in-documentation}{Mintlify's Trieve acquisition} signals retrieval quality is becoming core IP.
\end{itemize}
\end{frame}

% =============================================================================
% Sub-Market 2: Spec / Architecture / Design
% =============================================================================

\begin{frame}{Market 3.2: Spec / Architecture / Design---Key Players}
\input{Tables/P1M3-spec-design.tex}
\end{frame}

\begin{frame}{Market 3.2: Spec / Architecture / Design---Analysis}
\justifying
\small
\begin{itemize}
  \item \textbf{Market Size (\$5--8B TAM):} The combined market for API design (\citelink{https://www.postman.com/}{Postman} 30M+ developers), diagramming (\citelink{https://miro.com/}{Miro} 70M+ users, \citelink{https://www.lucidchart.com/}{Lucidchart} 70M+ users), and design-to-code (\citelink{https://www.figma.com/}{Figma} 4M+ users) represents \textcolor{red}{\$5--8B TAM}. This is a \textbf{fragmented market}---no single vendor owns the full ``spec-to-code'' workflow. Sub-segments (API-first, diagram-first, design-first) have distinct buyers and workflows.

  \item \textbf{Technical Moat (Medium--High):} The moat is \textbf{workflow centrality + standards enforcement}, not ``generate a diagram.'' Key moats: (1) \textbf{API contract governance}---\citelink{https://stoplight.io/}{Stoplight} and \citelink{https://swagger.io/tools/swaggerhub/}{SwaggerHub} enforce OpenAPI compliance with linting, versioning, approvals, mocking, compatibility checks; (2) \textbf{design system alignment}---\citelink{https://www.figma.com/}{Figma Dev Mode} connects designs to component libraries; (3) \textbf{SDK generation}---\citelink{https://buildwithfern.com/}{Fern} auto-generates client libraries from API specs.

  \item \textbf{AI Potential (Medium---50--70\%):} AI can generate diagrams from text (\citelink{https://eraser.io/}{Eraser AI}), produce UI components from prompts (\citelink{https://v0.dev/}{v0}), and draft API specs. However, \textbf{specs are negotiation artifacts}---system boundaries, scaling tradeoffs, and security implications resist full automation. The ``pre-coding'' phase is where \textbf{intent formation} happens; AI accelerates drafting but doesn't replace human alignment.
\end{itemize}
\end{frame}

% =============================================================================
% Sub-Market 3: Testing / QA
% =============================================================================

\begin{frame}{Market 3.3: Testing / QA---Key Players}
\input{Tables/P1M3-testing.tex}
\end{frame}

\begin{frame}{Market 3.3: Testing / QA---Analysis}
\justifying
\small
\begin{itemize}
  \item \textbf{Market Size (\$8--12B TAM):} Software testing is a \textcolor{red}{\$8--12B} market spanning unit testing, E2E testing, visual regression, and test infrastructure. \citelink{https://www.tricentis.com/}{Tricentis} (2,400+ enterprise customers, \$1.7B acquisition), \citelink{https://www.browserstack.com/}{BrowserStack} (50k+ customers, \$450M funding), and \citelink{https://applitools.com/}{Applitools} (800+ enterprise customers) demonstrate the market can support multiple large vendors. Testing is a \textbf{proven enterprise budget category}.

  \item \textbf{Technical Moat (High):} Testing tools have the \textbf{strongest technical moats} in Market 3: (1) \textbf{infrastructure scale}---device farms, browsers, regions that general agents cannot replicate; (2) \textbf{test signal + historical flakiness data}---vendor-specific advantage from CI telemetry; (3) \textbf{language-specific optimization}---\citelink{https://www.diffblue.com/}{Diffblue} achieves 90\%+ coverage on Java via bytecode analysis, not general LLM inference. Market 2 players can \textit{generate} tests but cannot \textit{execute} them at scale.

  \item \textbf{AI Potential (High---70--85\%):} The market shifts from ``generate tests'' to \textbf{``keep tests passing''}---self-heal locators, triage failures, prioritize suites. The ceiling: \textbf{test oracles / product intent}---AI can generate tests but struggles to know \textit{what correct behavior looks like} without human-specified assertions. E2E agents will integrate into execution platforms, not replace them.
\end{itemize}
\end{frame}

% =============================================================================
% Sub-Market 4: Code Review / PR Workflow
% =============================================================================

\begin{frame}{Market 3.4: Code Review / PR Workflow---Key Players}
\input{Tables/P1M3-code-review.tex}
\end{frame}

\begin{frame}{Market 3.4: Code Review / PR Workflow---Analysis}
\justifying
\small
\begin{itemize}
  \item \textbf{Market Size (\$3--5B TAM):} Code quality and review tools represent \textcolor{red}{\$3--5B TAM}. \citelink{https://www.sonarsource.com/}{SonarSource} (7M developers, 400k+ organizations, \$412M funding) dominates code quality gates. AI-native review is hot: \citelink{https://techcrunch.com/2025/09/16/coderabbit-raises-60m-valuing-the-2-year-old-ai-code-review-startup-at-550m/}{CodeRabbit's \$60M Series B at \$550M valuation} shows investor appetite. \citelink{https://news.nus.edu.sg/nus-spinoff-tech-autocoderover-acquired-by-sonar/}{Sonar acquired AutoCodeRover} for agentic code development.

  \item \textbf{Technical Moat (Medium):} Durable moats: (1) \textbf{rule libraries}---SonarQube has 5,000+ rules across 35+ languages; (2) \textbf{codebase history}---\citelink{https://codescene.com/}{CodeScene} analyzes git history to identify ``hotspots''; (3) \textbf{false-positive management + triage UX}. However, this is the \textbf{most vulnerable Market 3 vertical}---``AI review comments'' become table stakes; differentiation moves to \textbf{policy enforcement}, \textbf{blast radius scoring}, and \textbf{measurable defect reduction}.

  \item \textbf{AI Potential (Medium---50--70\%):} AI can catch obvious bugs, style violations, and security issues. The ceiling: \textbf{architectural judgment} and \textbf{business logic correctness}. The \textbf{threat}: IDE vendors and general agents will offer ``good enough review,'' squeezing standalone tools that don't own governance. Survivors pivot to \textbf{compliance} (audit trails, policy gates) and \textbf{analytics} (escaped defects, review cycle time).
\end{itemize}
\end{frame}

% =============================================================================
% Sub-Market 5: DevOps / CI/CD / Infrastructure
% =============================================================================

\begin{frame}{Market 3.5: DevOps / Infrastructure---Key Players}
\input{Tables/P1M3-devops.tex}
\end{frame}

\begin{frame}{Market 3.5: DevOps / Infrastructure---Analysis}
\justifying
\small
\begin{itemize}
  \item \textbf{Market Size (\$16--43B TAM):} DevOps/infrastructure is the \textcolor{red}{largest Market 3 vertical}---\citelink{https://www.mordorintelligence.com/industry-reports/devops-market}{Mordor estimates \$16.1B (2025) $\rightarrow$ \$43.2B (2030)}. \citelink{https://github.com/features/actions}{GitHub Actions} (100M+ developer platform) and \citelink{https://about.gitlab.com/}{GitLab CI} (30M+ users) dominate CI/CD. Platform engineering is booming: \citelink{https://www.getport.io/}{Port's \$100M Series C at \$800M valuation} and \citelink{https://devops.com/harness-acquires-qwiet-ai-to-gain-code-testing-tool/}{Harness's Qwiet AI acquisition} signal consolidation.

  \item \textbf{Technical Moat (Very High):} DevOps has the \textbf{strongest hard moat} in Market 3: (1) \textbf{cloud provider integration depth}---Pulumi, env0, Spacelift integrate with AWS/Azure/GCP resource models; (2) \textbf{state management}---IaC tools track drift that general agents cannot reason about; (3) \textbf{reliability + blast radius management}---production systems require controlled execution. \citelink{https://www.pulumi.com/product/neo/}{Pulumi Neo} is the canonical ``agentic platform engineer'' example---agent inside an enterprise governance model.

  \item \textbf{AI Potential (High for generation, Medium for execution---40--70\%):} AI can generate Terraform/Pulumi code, suggest configurations, and automate runbooks. However, \textbf{infrastructure changes are high-stakes}---production incidents from AI-generated IaC are costly. The near-term ceiling is \textbf{trust + determinism}: most enterprises will keep agents in ``recommend/prepare mode'' unless wrapped in governance shells with RBAC, approvals, and audit logs.
\end{itemize}
\end{frame}

% =============================================================================
% Sub-Market 6: Security / Compliance
% =============================================================================

\begin{frame}{Market 3.6: Security / Compliance---Key Players}
\input{Tables/P1M3-security.tex}
\end{frame}

\begin{frame}{Market 3.6: Security / Compliance---Analysis}
\justifying
\small
\begin{itemize}
  \item \textbf{Market Size (\$33.7B $\rightarrow$ \$55B TAM):} Application security is the \textcolor{red}{largest ``must-buy'' vertical}---\citelink{https://www.marketsandmarkets.com/Market-Reports/application-security-market-110170194.html}{MarketsandMarkets projects \$33.7B (2024) $\rightarrow$ \$55.0B (2029)}. Software supply-chain security alone is \citelink{https://www.mordorintelligence.com/industry-reports/software-supply-chain-security-platforms-market}{\$5.5B (2025) $\rightarrow$ \$10.1B (2030)}. \citelink{https://snyk.io/}{Snyk} (\$278.4M 2024 revenue), \citelink{https://checkmarx.com/}{Checkmarx} (\$1.15B acquisition), and \citelink{https://www.veracode.com/}{Veracode} (\$2.5B acquisition) demonstrate this is a \textbf{proven category with multiple unicorn-scale vendors}.

  \item \textbf{Technical Moat (Strongest in Market 3):} Security has the \textbf{strongest moats}: (1) \textbf{vulnerability databases}---Snyk, Sonatype maintain proprietary CVE intelligence updated daily; (2) \textbf{precision/recall + triage workflows}---matter more than ``LLM cleverness''; (3) \textbf{supply-chain intelligence}---\citelink{https://socket.dev/}{Socket} analyzes package behavior, not just known CVEs; (4) \textbf{compliance evidence}---audit logs, policy exceptions, risk acceptance. \citelink{https://checkmarx.com/press-releases/checkmarx-acquires-tromzo-to-launch-new-era-of-application-security/}{Checkmarx acquired Tromzo} for agentic AppSec posture.

  \item \textbf{AI Potential (Low--Medium---30--50\%):} Security has the \textcolor{red}{lowest AI automation ceiling} in Market 3. AI can triage alerts, prioritize vulns, generate fix suggestions, and automate compliance evidence. However, \textbf{false positives are costly} (alert fatigue), \textbf{false negatives are catastrophic} (missed vulnerabilities). Human security review will remain mandatory for: threat modeling, penetration testing, incident response. The ``liability and verification'' barrier limits full automation.
\end{itemize}
\end{frame}

% =============================================================================
% Cross-Market Patterns & Outlook
% =============================================================================

\begin{frame}{Market 3: Sub-Market Comparison Matrix}
\justifying
\input{Tables/P1M3-6submarkets.tex}
\end{frame}

\begin{frame}{Market 3: 6--12 Month Outlook---Macro Drivers}
\justifying
\small
\begin{itemize}
  \item \textbf{Budgets Shift to Risk + Governance:} In the next 6--12 months, the \textbf{fastest-growing} specialized categories will be \textbf{AppSec / supply-chain security} and \textbf{platform engineering / DevOps automation}, because they are tied to \textbf{board-level risk and production reliability} rather than developer preference. Developer AI adoption is already \citelink{https://survey.stackoverflow.co/2025/ai}{84\% using or planning} (Stack Overflow 2025), but \citelink{https://www.barrons.com/articles/ai-development-spending-79d225f5}{only 17\% deployed AI at scale} (UBS survey)---unclear ROI remains the top barrier.

  \item \textbf{Platform Engineering Becomes Control Plane:} \citelink{https://www.gartner.com/en/experts/top-tech-trends-unpacked-series/platform-engineering-empowers-developers}{Gartner predicts 80\% of large software engineering orgs will establish platform teams by 2026}. This drives spend on \textbf{internal developer platforms (IDPs) + policy engines} that can safely host agents. \citelink{https://info.pulumi.com/press-release/pulumi-neo}{Pulumi Neo} (``agentic platform engineer'') and \citelink{https://www.getport.io/}{Port} (\$800M valuation) exemplify the ``governance shell'' approach.

  \item \textbf{``Agentic'' Becomes Default Roadmap---With Gated Execution:} Most enterprises will move from chat-style helpers to agents that can \textbf{propose/prepare changes}, while \textbf{write-access} (merge, deploy, change infra) remains heavily permissioned. Expect explicit \textbf{action permissions per agent capability} (``can comment'' vs ``can open PR'' vs ``can merge'' vs ``can deploy'').
\end{itemize}
\end{frame}

\begin{frame}{Market 3: 6--12 Month Outlook---Consolidation \& Sub-Markets}
\justifying
\small
\begin{itemize}
  \item \textbf{Consolidation Accelerates (Platforms Buying Specialists):} 2025 M\&A pattern is clear---specialized capabilities pulled into larger platforms: \citelink{https://www.reuters.com/legal/transactional/openai-acquire-product-testing-startup-statsig-appoints-cto-applications-2025-09-02/}{OpenAI $\rightarrow$ Statsig}, \citelink{https://devops.com/harness-acquires-qwiet-ai-to-gain-code-testing-tool/}{Harness $\rightarrow$ Qwiet AI}, \citelink{https://checkmarx.com/press-releases/checkmarx-acquires-tromzo-to-launch-new-era-of-application-security/}{Checkmarx $\rightarrow$ Tromzo}, \citelink{https://news.nus.edu.sg/nus-spinoff-tech-autocoderover-acquired-by-sonar/}{Sonar $\rightarrow$ AutoCodeRover}, \citelink{https://www.mintlify.com/blog/mintlify-acquires-trieve-to-improve-rag-search-in-documentation}{Mintlify $\rightarrow$ Trieve}. With \citelink{https://www.reuters.com/technology/us-software-firm-freshworks-eyes-acquisitions-with-800-million-cash-pile-ai-2025-12-17/}{global M\&A up 39\% in 2025 to \$4.3T}, expect \textcolor{red}{more tuck-in acquisitions} where DevOps suites buy AppSec/policy, code quality incumbents buy ``agentic review,'' and docs platforms buy retrieval/eval infra.

  \item \textbf{Sub-Market Outlook:} \textbf{Documentation}---race to become ``answer systems'' (RAG + provenance); commoditization risk unless strongly code-coupled. \textbf{Testing}---shift from ``generate tests'' to ``keep tests passing''; E2E agents integrate into execution platforms. \textbf{Code Review}---``AI comments'' become table stakes; survivors own policy + compliance. \textbf{DevOps}---where agentic execution becomes real first (platform teams constrain actions with RBAC). \textbf{Security}---move from ``find vulns'' to \textbf{closed-loop remediation}: prioritize $\rightarrow$ generate fix $\rightarrow$ open PR $\rightarrow$ validate $\rightarrow$ audit evidence.

  \item \textbf{What to Watch (Early 2026):} (1) Policy primitives shipping: SCIM/audit logs + action permissions per agent; (2) Closed-loop metrics: \% vulns fixed automatically, MTTR reductions; (3) Platform engineering headcount expansion; (4) More acquisitions of risk scoring, posture management, retrieval + eval infrastructure.
\end{itemize}
\end{frame}
